// Only used in use-chat-handler.tsx to keep it clean
import { createClient } from "@/lib/supabase/client"

import { createChatFiles } from "@/db/chat-files"
import { createChat } from "@/db/chats"
import { createMessageFileItems } from "@/db/message-file-items"
import { createMessages, updateMessage } from "@/db/messages"
import { uploadMessageImage } from "@/db/storage/message-images"
import { buildFinalMessages } from "@/lib/build-prompt"
import { consumeReadableStream } from "@/lib/consume-stream"
import { Tables, TablesInsert } from "@/supabase/types"
import {
  ChatFile,
  ChatMessage,
  ChatPayload,
  ChatSettings,
  LLM,
  LLMID,
  MessageImage
} from "@/types"
import React from "react"
import { toast } from "sonner"
import { v4 as uuidv4 } from "uuid"

// Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ø¨Ø§Ù‚ÛŒ Ù…ÛŒâ€ŒÙ…Ø§Ù†Ø¯
export const validateChatSettings = (
  chatSettings: ChatSettings | null,
  modelData: LLM | undefined,
  profile: Tables<"profiles"> | null,
  selectedWorkspace: Tables<"workspaces"> | null,
  messageContent: string
) => {
  if (!chatSettings) {
    throw new Error("Chat settings not found")
  }
  if (!modelData) {
    throw new Error("Model not found")
  }
  if (!profile) {
    throw new Error("Profile not found")
  }
  if (!selectedWorkspace) {
    throw new Error("Workspace not found")
  }
  if (!messageContent) {
    throw new Error("Message content not found")
  }
}

// Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ø¨Ø§Ù‚ÛŒ Ù…ÛŒâ€ŒÙ…Ø§Ù†Ø¯
export const handleRetrieval = async (
  userInput: string,
  newMessageFiles: ChatFile[],
  chatFiles: ChatFile[],
  embeddingsProvider: "openai" | "local",
  sourceCount: number
) => {
  const response = await fetch("/api/retrieval/retrieve", {
    method: "POST",
    body: JSON.stringify({
      userInput,
      fileIds: [...newMessageFiles, ...chatFiles].map(file => file.id),
      embeddingsProvider,
      sourceCount
    })
  })

  if (!response.ok) {
    console.error("Error retrieving:", response)
  }

  const { results } = (await response.json()) as {
    results: Tables<"file_items">[]
  }

  return results
}

// Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ø¨Ø§Ù‚ÛŒ Ù…ÛŒâ€ŒÙ…Ø§Ù†Ø¯
export const createTempMessages = (
  messageContent: string,
  chatMessages: ChatMessage[],
  chatSettings: ChatSettings,
  b64Images: string[],
  isRegeneration: boolean,
  setChatMessages: React.Dispatch<React.SetStateAction<ChatMessage[]>>,
  selectedAssistant: Tables<"assistants"> | null
) => {
  let tempUserChatMessage: ChatMessage = {
    message: {
      chat_id: "",
      assistant_id: null,
      content: messageContent,
      created_at: "",
      id: uuidv4(),
      image_paths: b64Images,
      model: chatSettings.model,
      role: "user",
      sequence_number: chatMessages.length,
      updated_at: "",
      user_id: ""
    },
    fileItems: []
  }

  let tempAssistantChatMessage: ChatMessage = {
    message: {
      chat_id: "",
      assistant_id: selectedAssistant?.id || null,
      content: "",
      created_at: "",
      id: uuidv4(),
      image_paths: [],
      model: chatSettings.model,
      role: "assistant",
      sequence_number: chatMessages.length + 1,
      updated_at: "",
      user_id: ""
    },
    fileItems: []
  }

  let newMessages = []

  if (isRegeneration) {
    const lastMessageIndex = chatMessages.length - 1
    chatMessages[lastMessageIndex].message.content = ""
    newMessages = [...chatMessages]
  } else {
    newMessages = [
      ...chatMessages,
      tempUserChatMessage,
      tempAssistantChatMessage
    ]
  }

  setChatMessages(newMessages)

  return {
    tempUserChatMessage,
    tempAssistantChatMessage
  }
}

// âŒ ØªØ§Ø¨Ø¹ handleLocalChat Ø¨Ù‡ Ø·ÙˆØ± Ú©Ø§Ù…Ù„ Ø­Ø°Ù Ø´Ø¯

export const handleHostedChat = async (
  payload: ChatPayload,
  profile: Tables<"profiles">,
  modelData: LLM,
  tempAssistantChatMessage: ChatMessage,
  isRegeneration: boolean,
  newAbortController: AbortController,
  newMessageImages: MessageImage[],
  chatImages: MessageImage[],
  setIsGenerating: React.Dispatch<React.SetStateAction<boolean>>,
  setFirstTokenReceived: React.Dispatch<React.SetStateAction<boolean>>,
  setChatMessages: React.Dispatch<React.SetStateAction<ChatMessage[]>>,
  setToolInUse: React.Dispatch<React.SetStateAction<string>>,
  isNewProblem: boolean = false // <-- Ù¾Ø§Ø±Ø§Ù…ØªØ± Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø±ÛŒØ³Øª Ú©Ø±Ø¯Ù†
) => {
  console.log("ğŸ›« handleHostedChat started...")

  // Ù…Ù†Ø·Ù‚ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ ØªØ´Ø®ÛŒØµ provider Ùˆ Google Gemini Ø­Ø°Ù Ø´Ø¯
  let formattedMessages = await buildFinalMessages(payload, profile, chatImages)

  // Ø¢Ø¯Ø±Ø³ API Ù‡Ù…ÛŒØ´Ù‡ Ø«Ø§Ø¨Øª Ùˆ Ù…ØªØ¹Ù„Ù‚ Ø¨Ù‡ Ø´Ù…Ø§Ø³Øª
  const apiEndpoint = "https://api.porsino.org/chat"

  const requestBody = {
    message:
      payload.chatMessages[payload.chatMessages.length - 1].message.content,
    customModelId: payload.chatSettings.model,
    isNewProblem: isNewProblem // <-- ÙÙ„Ú¯ Ø¬Ø¯ÛŒØ¯ Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯
  }

  const response = await fetchChatResponse(
    apiEndpoint,
    requestBody,
    newAbortController,
    setIsGenerating,
    setChatMessages
  )

  // ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ processResponse Ø¨Ø§ Ù¾Ø§Ø±Ø§Ù…ØªØ± modelId Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ù¾Ø§Ø³Ø®
  return await processResponse(
    response,
    isRegeneration
      ? payload.chatMessages[payload.chatMessages.length - 1]
      : tempAssistantChatMessage,
    newAbortController,
    setFirstTokenReceived,
    setChatMessages,
    setToolInUse,
    payload.chatSettings.model // <-- Ù¾Ø§Ø±Ø§Ù…ØªØ± modelId
  )
}

export const fetchChatResponse = async (
  url: string,
  body: object,
  controller: AbortController,
  setIsGenerating: React.Dispatch<React.SetStateAction<boolean>>,
  setChatMessages: React.Dispatch<React.SetStateAction<ChatMessage[]>>
) => {
  const supabase = createClient()
  const session = await supabase.auth.getSession()
  const token = session.data.session?.access_token

  console.log("ğŸ“¡ Sending fetch to:", url)
  console.log("ğŸŸ¢ Request body:", body)

  const response = await fetch(url, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      ...(token && { Authorization: `Bearer ${token}` })
    },
    body: JSON.stringify(body),
    signal: controller.signal
  })

  if (!response.ok) {
    // Ø´Ø±Ø· Ù…Ø®ØµÙˆØµ Ø®Ø·Ø§ÛŒ Ollama Ø­Ø°Ù Ø´Ø¯
    const errorData = await response.json()
    const errorText =
      errorData?.detail && typeof errorData.detail === "string"
        ? errorData.detail
        : "Ø®Ø·Ø§ÛŒÛŒ Ø±Ø® Ø¯Ø§Ø¯Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯."

    toast.error(errorText)

    setIsGenerating(false)
    setChatMessages(prevMessages => prevMessages.slice(0, -2))
  }

  return response
}

export const processResponse = async (
  response: Response,
  lastChatMessage: ChatMessage,
  controller: AbortController,
  setFirstTokenReceived: React.Dispatch<React.SetStateAction<boolean>>,
  setChatMessages: React.Dispatch<React.SetStateAction<ChatMessage[]>>,
  setToolInUse: React.Dispatch<React.SetStateAction<string>>,
  modelId: LLMID // <-- Ù¾Ø§Ø±Ø§Ù…ØªØ± Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ù¾Ø§Ø³Ø®
) => {
  // Ø§Ú¯Ø± Ù…Ø¯Ù„ Ø±ÛŒØ§Ø¶ÛŒ Ø¨ÙˆØ¯ØŒ Ù¾Ø§Ø³Ø® JSON Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
  if (modelId === "math-advanced") {
    setFirstTokenReceived(true)
    setToolInUse("none")

    const payload = await response.json()
    const fullText = payload.answer || ""

    // Ø¯Ø± Ù…Ø±Ø§Ø­Ù„ Ø¨Ø¹Ø¯ØŒ state Ù‡Ø§ÛŒ topic_summary Ùˆ suggestions Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ø¢Ù¾Ø¯ÛŒØª Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    console.log("Math Agent Payload:", payload) // Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ùˆ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØªÛŒ

    setChatMessages(prev =>
      prev.map(chatMessage => {
        if (chatMessage.message.id === lastChatMessage.message.id) {
          const updatedChatMessage: ChatMessage = {
            message: { ...chatMessage.message, content: fullText },
            fileItems: chatMessage.fileItems
          }
          return updatedChatMessage
        }
        return chatMessage
      })
    )
    return fullText
  }

  // Ø¯Ø± ØºÛŒØ± Ø§ÛŒÙ† ØµÙˆØ±Øª (Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ³Øª)ØŒ Ù¾Ø§Ø³Ø® Ø±Ø§ Ø§Ø³ØªØ±ÛŒÙ… Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
  let fullText = ""
  if (response.body) {
    await consumeReadableStream(
      response.body,
      chunk => {
        setFirstTokenReceived(true)
        setToolInUse("none")

        // Ù…Ù†Ø·Ù‚ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ø¨Ø±Ø§ÛŒ Ollama Ø­Ø°Ù Ø´Ø¯Ù‡ Ùˆ ÙÙ‚Ø· chunk Ø¨Ø§Ù‚ÛŒ Ù…ÛŒâ€ŒÙ…Ø§Ù†Ø¯
        fullText += chunk

        setChatMessages(prev =>
          prev.map(chatMessage => {
            if (chatMessage.message.id === lastChatMessage.message.id) {
              const updatedChatMessage: ChatMessage = {
                message: { ...chatMessage.message, content: fullText },
                fileItems: chatMessage.fileItems
              }
              return updatedChatMessage
            }
            return chatMessage
          })
        )
      },
      controller.signal
    )
    return fullText
  } else {
    throw new Error("Response body is null")
  }
}

export const handleCreateChat = async (
  chatSettings: ChatSettings,
  profile: Tables<"profiles">,
  selectedWorkspace: Tables<"workspaces">,
  messageContent: string,
  selectedAssistant: Tables<"assistants">,
  newMessageFiles: ChatFile[],
  setSelectedChat: React.Dispatch<React.SetStateAction<Tables<"chats"> | null>>,
  setChats: React.Dispatch<React.SetStateAction<Tables<"chats">[]>>,
  setChatFiles: React.Dispatch<React.SetStateAction<ChatFile[]>>
) => {
  const createdChat = await createChat({
    user_id: profile.user_id,
    workspace_id: selectedWorkspace.id,
    assistant_id: selectedAssistant?.id || null,
    context_length: chatSettings.contextLength,
    include_profile_context: chatSettings.includeProfileContext,
    include_workspace_instructions: chatSettings.includeWorkspaceInstructions,
    model: chatSettings.model,
    name: messageContent.substring(0, 100),
    prompt: chatSettings.prompt,
    temperature: chatSettings.temperature,
    embeddings_provider: chatSettings.embeddingsProvider
  })

  setSelectedChat(createdChat)
  setChats(chats => [createdChat, ...chats])

  await createChatFiles(
    newMessageFiles.map(file => ({
      user_id: profile.user_id,
      chat_id: createdChat.id,
      file_id: file.id
    }))
  )

  setChatFiles(prev => [...prev, ...newMessageFiles])

  return createdChat
}

export const handleCreateMessages = async (
  chatMessages: ChatMessage[],
  currentChat: Tables<"chats">,
  profile: Tables<"profiles">,
  modelData: LLM,
  messageContent: string,
  generatedText: string,
  newMessageImages: MessageImage[],
  isRegeneration: boolean,
  retrievedFileItems: Tables<"file_items">[],
  setChatMessages: React.Dispatch<React.SetStateAction<ChatMessage[]>>,
  setChatFileItems: React.Dispatch<
    React.SetStateAction<Tables<"file_items">[]>
  >,
  setChatImages: React.Dispatch<React.SetStateAction<MessageImage[]>>,
  selectedAssistant: Tables<"assistants"> | null
) => {
  const finalUserMessage: TablesInsert<"messages"> = {
    chat_id: currentChat.id,
    assistant_id: null,
    user_id: profile.user_id,
    content: messageContent,
    model: modelData.modelId,
    role: "user",
    sequence_number: chatMessages.length,
    image_paths: []
  }

  const finalAssistantMessage: TablesInsert<"messages"> = {
    chat_id: currentChat.id,
    assistant_id: selectedAssistant?.id || null,
    user_id: profile.user_id,
    content: generatedText,
    model: modelData.modelId,
    role: "assistant",
    sequence_number: chatMessages.length + 1,
    image_paths: []
  }

  let finalChatMessages: ChatMessage[] = []

  if (isRegeneration) {
    const lastStartingMessage = chatMessages[chatMessages.length - 1].message

    const updatedMessage = await updateMessage(lastStartingMessage.id, {
      ...lastStartingMessage,
      content: generatedText
    })

    chatMessages[chatMessages.length - 1].message = updatedMessage

    finalChatMessages = [...chatMessages]

    setChatMessages(finalChatMessages)
  } else {
    const createdMessages = await createMessages([
      finalUserMessage,
      finalAssistantMessage
    ])

    // Upload each image (stored in newMessageImages) for the user message to message_images bucket
    const uploadPromises = newMessageImages
      .filter(obj => obj.file !== null)
      .map(obj => {
        let filePath = `${profile.user_id}/${currentChat.id}/${
          createdMessages[0].id
        }/${uuidv4()}`

        return uploadMessageImage(filePath, obj.file as File).catch(error => {
          console.error(`Failed to upload image at ${filePath}:`, error)
          return null
        })
      })

    const paths = (await Promise.all(uploadPromises)).filter(
      Boolean
    ) as string[]

    setChatImages(prevImages => [
      ...prevImages,
      ...newMessageImages.map((obj, index) => ({
        ...obj,
        messageId: createdMessages[0].id,
        path: paths[index]
      }))
    ])

    const updatedMessage = await updateMessage(createdMessages[0].id, {
      ...createdMessages[0],
      image_paths: paths
    })

    const createdMessageFileItems = await createMessageFileItems(
      retrievedFileItems.map(fileItem => {
        return {
          user_id: profile.user_id,
          message_id: createdMessages[1].id,
          file_item_id: fileItem.id
        }
      })
    )

    finalChatMessages = [
      ...chatMessages,
      {
        message: updatedMessage,
        fileItems: []
      },
      {
        message: createdMessages[1],
        fileItems: retrievedFileItems.map(fileItem => fileItem.id)
      }
    ]

    setChatFileItems(prevFileItems => {
      const newFileItems = retrievedFileItems.filter(
        fileItem => !prevFileItems.some(prevItem => prevItem.id === fileItem.id)
      )

      return [...prevFileItems, ...newFileItems]
    })

    setChatMessages(finalChatMessages)
  }
}
